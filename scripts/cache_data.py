"""
Code de diagnostic pour identifier les probl√®mes dans vos donn√©es
Ex√©cutez ce code AVANT de continuer l'entra√Ænement
"""

import pandas as pd
import numpy as np
from crypto_signals.src.train_lgbm import prepare


def diagnostic_complet(symbol="BTCUSDT"):
    """Diagnostic complet des donn√©es d'entra√Ænement."""
    print(f"=== DIAGNOSTIC POUR {symbol} ===\n")

    # 1. Charger les donn√©es
    df = prepare(symbol)
    print(f"üìä Nombre total de lignes: {len(df)}")

    # 2. Analyser la distribution du target
    target_dist = df['target'].value_counts()
    print(f"\nüéØ Distribution du target:")
    print(f"  - Classe 0 (pas de hit): {target_dist[0]} ({target_dist[0] / len(df) * 100:.1f}%)")
    print(f"  - Classe 1 (hit): {target_dist[1]} ({target_dist[1] / len(df) * 100:.1f}%)")

    # 3. V√©rifier la fuite de donn√©es
    print(f"\nüîç V√©rification de la fuite de donn√©es:")

    # Calculer manuellement le target sans fuite
    margin = 0.0016
    horizon = 5

    # M√©thode actuelle (avec fuite potentielle)
    current_target = df['target'].copy()

    # M√©thode corrig√©e
    corrected_targets = []
    for i in range(len(df)):
        if i + horizon < len(df):
            future_high = df["high"].iloc[i + 1:i + 1 + horizon].max()
            hit = future_high >= df["close"].iloc[i] * (1 + margin)
            corrected_targets.append(int(hit))
        else:
            corrected_targets.append(np.nan)

    df['target_corrected'] = corrected_targets
    df_clean = df.dropna()

    # Comparer les distributions
    if len(df_clean) > 0:
        corrected_dist = df_clean['target_corrected'].value_counts()
        print(f"  - Target corrig√© - Classe 0: {corrected_dist[0]} ({corrected_dist[0] / len(df_clean) * 100:.1f}%)")
        print(f"  - Target corrig√© - Classe 1: {corrected_dist[1]} ({corrected_dist[1] / len(df_clean) * 100:.1f}%)")

        # Diff√©rence entre les deux m√©thodes
        diff = (df_clean['target'] != df_clean['target_corrected']).sum()
        print(f"  - Diff√©rences entre m√©thodes: {diff} lignes ({diff / len(df_clean) * 100:.1f}%)")

    # 4. Analyser les features
    print(f"\nüìà Analyse des features:")
    for col in ['close', 'ret_1', 'ret_5', 'vol_30']:
        if col in df.columns:
            print(f"  - {col}: min={df[col].min():.6f}, max={df[col].max():.6f}, std={df[col].std():.6f}")

    # 5. V√©rifier les valeurs manquantes
    missing = df.isnull().sum()
    if missing.sum() > 0:
        print(f"\n‚ùå Valeurs manquantes d√©tect√©es:")
        print(missing[missing > 0])
    else:
        print(f"\n‚úÖ Pas de valeurs manquantes")

    # 6. Analyser la corr√©lation avec le futur (signe de fuite)
    print(f"\nüîÆ Corr√©lation avec les prix futurs (signe de fuite):")
    if 'ret_1' in df.columns:
        future_ret = df['ret_1'].shift(-1)
        correlation = df['ret_1'].corr(future_ret)
        print(f"  - Corr√©lation ret_1 avec ret_1 futur: {correlation:.4f}")
        if abs(correlation) > 0.05:
            print(f"  ‚ö†Ô∏è  Corr√©lation √©lev√©e d√©tect√©e - possible fuite!")

    # 7. Tester la pr√©dictibilit√© baseline
    print(f"\nüé≤ Test de pr√©dictibilit√© baseline:")

    # Mod√®le naive : pr√©dire toujours la classe majoritaire
    majority_class = df['target'].mode()[0]
    baseline_accuracy = (df['target'] == majority_class).mean()
    print(f"  - Accuracy baseline (toujours {majority_class}): {baseline_accuracy:.4f}")

    # Si accuracy > 0.95, c'est suspect
    if baseline_accuracy > 0.95:
        print(f"  ‚ö†Ô∏è  Accuracy baseline tr√®s √©lev√©e - donn√©es d√©s√©quilibr√©es!")

    # 8. V√©rifier les outliers
    print(f"\nüìä Analyse des outliers:")
    close_q99 = df['close'].quantile(0.99)
    close_q01 = df['close'].quantile(0.01)
    outliers = ((df['close'] > close_q99) | (df['close'] < close_q01)).sum()
    print(f"  - Outliers de prix (1% extr√™mes): {outliers} ({outliers / len(df) * 100:.1f}%)")

    return df


def test_validation_split():
    """Test de la validation crois√©e pour d√©tecter les fuites."""
    print(f"\n=== TEST DE VALIDATION CROIS√âE ===")

    # Simuler des donn√©es avec fuite connue
    np.random.seed(42)
    n_samples = 1000

    # Cr√©er des donn√©es avec fuite intentionnelle
    X = np.random.randn(n_samples, 5)
    y = np.random.randint(0, 2, n_samples)

    # Introduire une fuite : les features d√©pendent du futur
    for i in range(n_samples - 10):
        if y[i + 5] == 1:  # Si le target futur est 1
            X[i, 0] += 2  # Augmenter une feature

    # Tester avec validation crois√©e classique vs temporelle
    from crypto_signals.src.utils.custom_metrics import cross_val_score, KFold, LogisticRegression

    # Validation classique (shuffle)
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    scores_shuffle = cross_val_score(LogisticRegression(), X, y, cv=kfold)

    # Validation temporelle (sans shuffle)
    kfold_temporal = KFold(n_splits=5, shuffle=False)
    scores_temporal = cross_val_score(LogisticRegression(), X, y, cv=kfold_temporal)

    print(f"  - Score avec shuffle: {scores_shuffle.mean():.4f} (¬±{scores_shuffle.std():.4f})")
    print(f"  - Score temporel: {scores_temporal.mean():.4f} (¬±{scores_temporal.std():.4f})")

    if scores_shuffle.mean() > scores_temporal.mean() + 0.1:
        print(f"  ‚ö†Ô∏è  Diff√©rence significative d√©tect√©e - possible fuite de donn√©es!")

    return scores_shuffle, scores_temporal


# Ex√©cuter le diagnostic
if __name__ == "__main__":
    # Diagnostic principal
    df = diagnostic_complet("BTCUSDT")

    # Test de validation
    test_validation_split()

    print(f"\n" + "=" * 60)
    print("RECOMMANDATIONS:")
    print("1. Si diff√©rences dans les targets > 5%, corrigez la fuite")
    print("2. Si accuracy baseline > 95%, r√©√©quilibrez les donn√©es")
    print("3. Si corr√©lation future > 0.05, v√©rifiez vos features")
    print("4. Si scores shuffle >> temporel, impl√©mentez validation temporelle")
    print("=" * 60)
